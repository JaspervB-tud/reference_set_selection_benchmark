{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import seaborn as sns\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = [\n",
    "    \"order\",\n",
    "    \"family\",\n",
    "    \"genus\",\n",
    "]\n",
    "METHODS = [\n",
    "    \"all\",\n",
    "\t\"centroid\",\n",
    "    \"ggrasp\",\n",
    "    \"meshclust_0.95\",\n",
    "\t\"meshclust_0.97\",\n",
    "\t\"meshclust_0.99\",\n",
    "    \"gclust_0.95\",\n",
    "\t\"gclust_0.97\",\n",
    "\t\"gclust_0.99\",\n",
    "    \"single-linkage_0.95\",\n",
    "\t\"single-linkage_0.97\",\n",
    "\t\"single-linkage_0.99\",\n",
    "\t\"complete-linkage_0.95\",\n",
    "\t\"complete-linkage_0.97\",\n",
    "\t\"complete-linkage_0.99\",\n",
    "]\n",
    "# Labels for plotting\n",
    "METHOD_LABELS = {\n",
    "    \"all\": \"All\",\n",
    "    \"centroid\": \"Centroid\",\n",
    "    \"ggrasp\": \"GGRaSP\",\n",
    "    \"meshclust_0.95\": \"MC-0.95\",\n",
    "    \"meshclust_0.97\": \"MC-0.97\",\n",
    "    \"meshclust_0.99\": \"MC-0.99\",\n",
    "    \"gclust_0.95\": \"GC-0.95\",\n",
    "    \"gclust_0.97\": \"GC-0.97\",\n",
    "    \"gclust_0.99\": \"GC-0.99\",\n",
    "    \"single-linkage_0.95\": \"SL-0.95\",\n",
    "    \"single-linkage_0.97\": \"SL-0.97\",\n",
    "    \"single-linkage_0.99\": \"SL-0.99\",\n",
    "    \"complete-linkage_0.95\": \"CL-0.95\",\n",
    "    \"complete-linkage_0.97\": \"CL-0.97\",\n",
    "    \"complete-linkage_0.99\": \"CL-0.99\"\n",
    "}\n",
    "OUTPUT_DIR = \"figures/bacteria\"\n",
    "\n",
    "ALPHA = 0.05 #significance level after multiple testing correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All experimental conditions (not all of NCBI)\n",
    "This will produce the supplementary figures S1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CI(refset1, refset2):\n",
    "    if type(refset1) is np.ndarray:\n",
    "        intersection = np.sum(np.minimum(refset1, refset2))\n",
    "        return [intersection/np.sum(refset1), intersection/np.sum(refset2)]\n",
    "    else:\n",
    "        intersection = len(refset1.intersection(refset2))\n",
    "        return [intersection/len(refset1), intersection/len(refset2)]\n",
    "\n",
    "def determine_nonsingletons(experiment):\n",
    "    \"\"\"\n",
    "    This function determines the species which have more than one genome and should be included\n",
    "    in the overlap analysis.\n",
    "    \"\"\"\n",
    "    path = f\"root/reference_sets/{experiment}_experiments/all.tsv\"\n",
    "    count_per_species = {}\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            species, _, _ = line.strip().split(\"\\t\")\n",
    "            if species not in count_per_species:\n",
    "                count_per_species[species] = 0\n",
    "            count_per_species[species] += 1\n",
    "    nonsingletons = [int(species) for species, count in count_per_species.items() if count > 1]\n",
    "    return sorted(nonsingletons)\n",
    "    \n",
    "def determine_content(experiment, method, nonsingletons):\n",
    "    \"\"\"\n",
    "    This function determines the content of a reference set for a given experiment and method.\n",
    "    NOTE: If a method was used with a threshold (e.g. gclust and 0.95) then the method name\n",
    "    should be provided as gclust_0.95.\n",
    "    \"\"\"\n",
    "    path = f\"root/reference_sets/{experiment}_experiments/{method}.tsv\"\n",
    "    counts = np.zeros(len(nonsingletons), dtype=int)\n",
    "    items = set()\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            species, accession, _ = line.strip().split(\"\\t\")\n",
    "            species = int(species)\n",
    "            if species in nonsingletons:\n",
    "                idx = nonsingletons.index(species)\n",
    "                counts[idx] += 1\n",
    "                items.add(accession)\n",
    "    return counts, items\n",
    "\n",
    "def simulate(N, n1, n2, obs_ci, num_simulations=10_000, seed=None):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo simulation to estimate the probability of observing a certain overlap between two sets.\n",
    "    NOTE: We specifically test whether the selection of n2 is independent of n1, i.e. we test the null hypothesis\n",
    "    that the selection of n2 is random with respect to n1 (thus the n1 draws are fixed). This means that the p-values \n",
    "    we obtain are one-sided, i.e. we only test whether the overlap is significantly greater than expected by chance.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    N: numpy.ndarray\n",
    "        A 1D vector with an entry for every nonsingleton species, indicating the total number of genomes\n",
    "        for that species that could be selected (i.e. are in the \"all\" reference set).\n",
    "    n1: numpy.ndarray\n",
    "        A 1D vector with an entry for every nonsingleton species, indicating the number of genomes\n",
    "        selected in the first set.\n",
    "    n2: numpy.ndarray\n",
    "        A 1D vector with an entry for every nonsingleton species, indicating the number of genomes\n",
    "        selected in the second set.\n",
    "    num_simulations: int\n",
    "        The number of Monte Carlo simulations to perform.\n",
    "    seed: int, optional\n",
    "        Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = np.asarray(N, dtype=int)\n",
    "    n1 = np.asarray(n1, dtype=int)\n",
    "    n2 = np.asarray(n2, dtype=int)\n",
    "    G = N.shape[0]\n",
    "\n",
    "    # simulate overlaps\n",
    "    sim_totals = np.zeros(num_simulations, dtype=int)\n",
    "    for Ng, n1g, n2g in zip(N, n1, n2):\n",
    "        draws = rng.hypergeometric(\n",
    "            ngood=int(n1g),\n",
    "            nbad=int(Ng-n1g),\n",
    "            nsample=int(n2g),\n",
    "            size=num_simulations\n",
    "        )\n",
    "        sim_totals += draws\n",
    "\n",
    "    sim_ci = sim_totals / np.sum(n2)\n",
    "\n",
    "    # Estimate p-values\n",
    "    def pval(sim, obs):\n",
    "        count = np.sum(sim >= obs)\n",
    "        p = (1 + count) / (1 + num_simulations)\n",
    "        se = sqrt(p * (1 - p) / num_simulations)\n",
    "        return p, se\n",
    "\n",
    "    return pval(sim_ci, obs_ci)\n",
    "\n",
    "def BH_adjust(pvalues, alpha):\n",
    "    \"\"\"\n",
    "    Benjamini-Hochberg procedure to control the false discovery rate (FDR) for multiple hypothesis testing.\n",
    "    \"\"\"\n",
    "    M = pvalues.shape[0]\n",
    "    \n",
    "    mask = ~np.eye(M, dtype=bool)\n",
    "    pvec = pvalues[mask]\n",
    "\n",
    "    m = len(pvec)\n",
    "\n",
    "    order = np.argsort(pvec)\n",
    "    psorted = pvec[order]\n",
    "    ranks = np.arange(1, m+1)\n",
    "    adj_sorted = psorted * m / ranks\n",
    "    adj_sorted = np.minimum.accumulate(adj_sorted[::-1])[::-1]\n",
    "    adj = np.empty_like(pvec)\n",
    "    adj[order] = np.minimum(adj_sorted, 1.0)\n",
    "\n",
    "    adj_pvalues = np.ones_like(pvalues)\n",
    "    adj_pvalues[mask] = adj\n",
    "    significant = adj_pvalues < alpha\n",
    "    return significant, adj_pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual plotting script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in EXPERIMENTS: # iterate over experiments\n",
    "    # Determine nonsingletons and reference sets\n",
    "    ns = determine_nonsingletons(experiment)\n",
    "    reference_sets = {\n",
    "        method: determine_content(experiment, method, ns) for method in METHODS\n",
    "    }\n",
    "    # Initialize matrices to store containment indices and p-values\n",
    "    containment_indices = np.ones((len(METHODS), len(METHODS)), dtype=np.float64)\n",
    "    pvalues = np.ones((len(METHODS), len(METHODS)), dtype=np.float64)\n",
    "    annot_matrix = np.empty_like(containment_indices, dtype=object) # annotation matrix for plotting\n",
    "    # Calculate containment indices and p-values for all method pairs\n",
    "    for i, method1 in tqdm(enumerate(METHODS)):\n",
    "        for j, method2 in enumerate(METHODS):\n",
    "            if i != j:\n",
    "                n1, r1 = reference_sets[method1]\n",
    "                n2, r2 = reference_sets[method2]\n",
    "                obs_ci = calculate_CI(r1, r2)[1]\n",
    "                containment_indices[j, i] = obs_ci\n",
    "                pvalues[j,i] = simulate(reference_sets[\"all\"][0], n1, n2, obs_ci, seed=i*10000 + j)[0]\n",
    "    # Correct for multiple testing\n",
    "    significant_pairs, _ = BH_adjust(pvalues, alpha=ALPHA)\n",
    "    for i, _ in tqdm(enumerate(METHODS)):\n",
    "        for j, _ in enumerate(METHODS):\n",
    "            if significant_pairs[i,j]:\n",
    "                annot_matrix[i,j] = f\"{containment_indices[i,j]:.2f}*\"\n",
    "            else:\n",
    "                annot_matrix[i,j] = f\"{containment_indices[i,j]:.2f}\"\n",
    "    # Start plotting\n",
    "    method_names = [METHOD_LABELS[method] for method in METHODS]\n",
    "    fig = plt.figure()\n",
    "    sns.heatmap(\n",
    "        containment_indices[:, 1:], \n",
    "        annot=annot_matrix[:, 1:], \n",
    "        cmap=\"Greys\",\n",
    "        cbar=True,\n",
    "        linewidth=0.5,\n",
    "        xticklabels=method_names[1:],\n",
    "        yticklabels=method_names,\n",
    "        fmt=\"\",\n",
    "        annot_kws={\"size\": 4},\n",
    "        )\n",
    "    plt.title(f\"{experiment.capitalize()} experiments\", size=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/{experiment}/containment_indices.pdf\", dpi=500, bbox_inches=\"tight\") #assumes folders etc exist\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCBI Bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_nonsingletons_global():\n",
    "    path = f\"root/reference_sets/all.tsv\"\n",
    "    count_per_species = {}\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            species, _, _ = line.strip().split(\"\\t\")\n",
    "            if species not in count_per_species:\n",
    "                count_per_species[species] = 0\n",
    "            count_per_species[species] += 1\n",
    "    nonsingletons = [int(species) for species, count in count_per_species.items() if count > 1]\n",
    "    return sorted(nonsingletons)\n",
    "    \n",
    "def determine_content_global(method, nonsingletons):\n",
    "    path = f\"root/reference_sets/{method}.tsv\"\n",
    "    counts = np.zeros(len(nonsingletons), dtype=int)\n",
    "    items = set()\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            species, accession, _ = line.strip().split(\"\\t\")\n",
    "            species = int(species)\n",
    "            if species in nonsingletons:\n",
    "                idx = nonsingletons.index(species)\n",
    "                counts[idx] += 1\n",
    "                items.add(accession)\n",
    "    return counts, items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = determine_nonsingletons_global()\n",
    "reference_sets = {\n",
    "    method: determine_content_global(method, ns) for method in METHODS\n",
    "}\n",
    "containment_indices = np.ones((len(METHODS), len(METHODS)), dtype=np.float64)\n",
    "pvalues = np.ones((len(METHODS), len(METHODS)), dtype=np.float64)\n",
    "annot_matrix = np.empty_like(containment_indices, dtype=object)\n",
    "for i, method1 in enumerate(METHODS):\n",
    "    for j, method2 in enumerate(METHODS):\n",
    "        if i != j:\n",
    "            n1, r1 = reference_sets[method1]\n",
    "            n2, r2 = reference_sets[method2]\n",
    "            obs_ci = calculate_CI(r1, r2)[1]\n",
    "            containment_indices[j, i] = obs_ci\n",
    "            pvalues[j,i] = simulate(reference_sets[\"all\"][0], n1, n2, obs_ci, seed=i*10000 + j)[0]\n",
    "# Correct for multiple testing\n",
    "significant_pairs, _ = BH_adjust(pvalues, alpha=ALPHA)\n",
    "for i, _ in enumerate(METHODS):\n",
    "    for j, _ in enumerate(METHODS):\n",
    "        if significant_pairs[i,j]:\n",
    "            annot_matrix[i,j] = f\"{containment_indices[i,j]:.2f}*\"\n",
    "        else:\n",
    "            annot_matrix[i,j] = f\"{containment_indices[i,j]:.2f}\"\n",
    "method_names = [METHOD_LABELS[method] for method in METHODS]\n",
    "sns.heatmap(\n",
    "    containment_indices[:, 1:], \n",
    "    annot=annot_matrix[:, 1:], \n",
    "    cmap=\"Greys\",\n",
    "    cbar=True,\n",
    "    linewidth=0.5,\n",
    "    xticklabels=method_names[1:],\n",
    "    yticklabels=method_names,\n",
    "    fmt=\"\",\n",
    "    annot_kws={\"size\": 4},\n",
    "    )\n",
    "plt.title(f\"NCBI Bacteria\", size=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/containment_indices.pdf\", dpi=500, bbox_inches=\"tight\", format=\"pdf\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core genomes figure\n",
    "This will produce the figures in supplementary figure S7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All experimental conditions (not all of NCBI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_content_coreset(experiment, method):\n",
    "    path = f\"root/reference_sets/{experiment}_experiments/{method}.tsv\"\n",
    "    genomes_per_species = {}\n",
    "    succesfully_selected = set()\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            species, accession, selected = line.strip().split(\"\\t\")\n",
    "            if species not in genomes_per_species:\n",
    "                genomes_per_species[species] = set()\n",
    "            genomes_per_species[species].add(accession)\n",
    "            if selected == \"+\": # account for species where selection method failed as these were randomly selected\n",
    "                succesfully_selected.add(species)\n",
    "    return genomes_per_species, succesfully_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The idea here is to generate a figure (one per experiment) that shows how many species (percentually) have a genome in the core set. The x-axis shows the\n",
    "cut-off (i.e. the minimum number of genomes in \"all\") and the y-axis shows the percentage of species with at least one genome in the core set.\n",
    "This requires:\n",
    "    - Determining the which genomes are selected for which species for all methods\n",
    "    - For each cut-off, determine the number of species that have at least one genome in the core set\n",
    "        + this can be achieved using set intersections\n",
    "\"\"\"\n",
    "for experiment in EXPERIMENTS:\n",
    "    reference_sets = {\n",
    "        method: determine_content_coreset(experiment, method) for method in METHODS\n",
    "    } #maps method to (genomes per species, successful species)\n",
    "    max_species = 0 #max for the x-axis -> max number of genomes in \"all\" for any species\n",
    "    # Coresets per species\n",
    "    coresets_per_species = {}\n",
    "    coresets_per_species_centroid = {}\n",
    "    for s in reference_sets[\"all\"][0]:\n",
    "        max_species = max(max_species, len(reference_sets[\"all\"][0][s]))\n",
    "        coresets_per_species[s] = reference_sets[\"all\"][0][s].copy()\n",
    "        coresets_per_species_centroid[s] = reference_sets[\"all\"][0][s].copy()\n",
    "        coresets_per_species_centroid[s] = coresets_per_species_centroid[s].intersection(reference_sets[\"centroid\"][0][s])\n",
    "        for method in METHODS[2:]: #skip 'all' and 'centroid'\n",
    "            if s in reference_sets[method][1]: #only consider species where method succeeded\n",
    "                coresets_per_species[s] = coresets_per_species[s].intersection(reference_sets[method][0][s]) #contains the genomes shared by every method for every species\n",
    "                coresets_per_species_centroid[s] = coresets_per_species_centroid[s].intersection(reference_sets[method][0][s])\n",
    "    total_per_cutoff = []\n",
    "    total_genomes_per_cutoff = []\n",
    "    num_per_cutoff = []\n",
    "    num_per_cutoff_centroid = []\n",
    "    coreset_per_cutoff = []\n",
    "    coreset_per_cutoff_centroid = []\n",
    "\n",
    "    lb = 1\n",
    "    for cutoff in range(lb, max_species+1):\n",
    "        cur_species = set()\n",
    "        cur_total = 0\n",
    "        for s in reference_sets[\"all\"][0]:\n",
    "            if len(reference_sets[\"all\"][0][s]) >= cutoff:\n",
    "                cur_species.add(s)\n",
    "                cur_total += len(reference_sets[\"all\"][0][s])\n",
    "        total_per_cutoff.append(len(cur_species))\n",
    "        total_genomes_per_cutoff.append(cur_total)\n",
    "        num_species_in_coreset = 0\n",
    "        num_species_in_coreset_centroid = 0\n",
    "        num_genomes_in_coreset = 0\n",
    "        num_genomes_in_coreset_centroid = 0\n",
    "        for species in cur_species:\n",
    "            if len(coresets_per_species[species]) > 0:\n",
    "                num_species_in_coreset += 1\n",
    "                num_genomes_in_coreset += len(coresets_per_species[species])\n",
    "            if len(coresets_per_species_centroid[species]) > 0:\n",
    "                num_species_in_coreset_centroid += 1\n",
    "                num_genomes_in_coreset_centroid += len(coresets_per_species_centroid[species])\n",
    "        num_per_cutoff.append(num_species_in_coreset)\n",
    "        num_per_cutoff_centroid.append(num_species_in_coreset_centroid)\n",
    "        coreset_per_cutoff.append(num_genomes_in_coreset)\n",
    "        coreset_per_cutoff_centroid.append(num_genomes_in_coreset_centroid)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(range(lb, max_species+1), total_per_cutoff, color=\"green\", linewidth=1, label=\"Total number of species\")\n",
    "    ax.plot(range(lb, max_species+1), num_per_cutoff, color=\"blue\", alpha=0.5, label=\"Number of species in coreset (excl. centroid)\")\n",
    "    ax.plot(range(lb, max_species+1), num_per_cutoff_centroid, color=\"orange\", alpha=0.5, label=\"Number of species in coreset (incl. centroid)\")\n",
    "    ax.set_xlabel(\"Minimal number of genomes per species\")\n",
    "    ax.set_ylabel(\"Number of species\")\n",
    "    ax.set_xlim(lb, max_species)\n",
    "    ax.set_xscale(\"log\", base=10)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_title(f\"Experiment: {experiment.capitalize()}\")\n",
    "    ax.legend()\n",
    "    # Add annotation for sets with >= 2 genomes\n",
    "    ax.vlines(2, ymin=0, ymax=num_per_cutoff_centroid[1], color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "    ax.vlines(2, ymin=num_per_cutoff_centroid[1], ymax=num_per_cutoff[1], color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "    ax.vlines(2, ymin=num_per_cutoff[1], ymax=total_per_cutoff[1], color=\"green\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(num_per_cutoff_centroid[1], xmin=lb, xmax=2, color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(num_per_cutoff[1], xmin=lb, xmax=2, color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(total_per_cutoff[1], xmin=lb, xmax=2, color=\"green\", linestyles=\":\", linewidth=1)\n",
    "    xticks = list(ax.get_xticks()) + [2]\n",
    "    yticks = list(ax.get_yticks()) + [num_per_cutoff_centroid[1]] +  [num_per_cutoff[1]] + [total_per_cutoff[1]]\n",
    "    ax.set_yticks(sorted(set(yticks)))\n",
    "    # Color\n",
    "    for label in ax.get_yticklabels():\n",
    "        if label.get_text() == f\"{num_per_cutoff_centroid[1]}\":\n",
    "            label.set_color(\"orange\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "        elif label.get_text() == f\"{num_per_cutoff[1]}\":\n",
    "            label.set_color(\"blue\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "        elif label.get_text() == f\"{total_per_cutoff[1]}\":\n",
    "            label.set_color(\"green\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/{experiment}/coreset_species.pdf\", dpi=500, bbox_inches=\"tight\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    #ax.plot(range(lb, max_species+1), total_genomes_per_cutoff, color=\"black\", linewidth=1, label=\"Total number of genomes\")\n",
    "    ax.plot(range(lb, max_species+1), coreset_per_cutoff, color=\"blue\", alpha=0.5, label=\"Number of genomes in coreset (excl. centroid)\")\n",
    "    ax.plot(range(lb, max_species+1), coreset_per_cutoff_centroid, color=\"orange\", alpha=0.5, label=\"Number of genomes in coreset (incl. centroid)\")\n",
    "    ax.set_xlabel(\"Minimal number of genomes per species\")\n",
    "    ax.set_ylabel(\"Number of genomes\")\n",
    "    ax.set_xlim(lb, max_species)\n",
    "    ax.set_xscale(\"log\", base=10)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_title(f\"Experiment: {experiment.capitalize()}\")\n",
    "    ax.legend()\n",
    "    # Add annotation for sets with >= 2 genomes\n",
    "    ax.vlines(2, ymin=0, ymax=coreset_per_cutoff_centroid[1], color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "    ax.vlines(2, ymin=coreset_per_cutoff_centroid[1], ymax=coreset_per_cutoff[1], color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(coreset_per_cutoff_centroid[1], xmin=lb, xmax=2, color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(coreset_per_cutoff[1], xmin=lb, xmax=2, color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "    xticks = list(ax.get_xticks()) + [2]\n",
    "    yticks = list(ax.get_yticks()) + [coreset_per_cutoff_centroid[1]] +  [coreset_per_cutoff[1]]\n",
    "    ax.set_yticks(sorted(set(yticks)))\n",
    "    # Color\n",
    "    for label in ax.get_yticklabels():\n",
    "        if label.get_text() == f\"{coreset_per_cutoff_centroid[1]}\":\n",
    "            label.set_color(\"orange\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "        elif label.get_text() == f\"{coreset_per_cutoff[1]}\":\n",
    "            label.set_color(\"blue\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/{experiment}/coreset_genomes.pdf\", dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCBI Bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_content_coreset_global(method):\n",
    "    path = f\"root/reference_sets/{method}.tsv\"\n",
    "    genomes_per_species = {}\n",
    "    succesfully_selected = set()\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            species, accession, selected = line.strip().split(\"\\t\")\n",
    "            if species not in genomes_per_species:\n",
    "                genomes_per_species[species] = set()\n",
    "            genomes_per_species[species].add(accession)\n",
    "            if selected == \"+\": # account for species where selection method failed as these were randomly selected\n",
    "                succesfully_selected.add(species)\n",
    "    return genomes_per_species, succesfully_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The idea here is to generate a figure (one per experiment) that shows how many species (percentually) have a genome in the core set. The x-axis shows the\n",
    "cut-off (i.e. the minimum number of genomes in \"all\") and the y-axis shows the percentage of species with at least one genome in the core set.\n",
    "This requires:\n",
    "    - Determining the which genomes are in which species for all methods\n",
    "    - For each cut-off, determine the number of species that have at least one genome in the core set\n",
    "        + this can be achieved using set intersections\n",
    "\"\"\"\n",
    "reference_sets = {\n",
    "    method: determine_content_coreset_global(method) for method in METHODS\n",
    "} #maps method to (genomes per species, successful species)\n",
    "max_species = 0 #max for the x-axis -> max number of genomes in \"all\" for any species\n",
    "# Coresets per species\n",
    "coresets_per_species = {}\n",
    "coresets_per_species_centroid = {}\n",
    "for s in reference_sets[\"all\"][0]:\n",
    "    max_species = max(max_species, len(reference_sets[\"all\"][0][s]))\n",
    "    coresets_per_species[s] = reference_sets[\"all\"][0][s].copy()\n",
    "    coresets_per_species_centroid[s] = reference_sets[\"all\"][0][s].copy()\n",
    "    coresets_per_species_centroid[s] = coresets_per_species_centroid[s].intersection(reference_sets[\"centroid\"][0][s])\n",
    "    for method in METHODS[2:]: #skip 'all' and 'centroid'\n",
    "        if s in reference_sets[method][1]: #only consider species where method succeeded\n",
    "            coresets_per_species[s] = coresets_per_species[s].intersection(reference_sets[method][0][s]) #contains the genomes shared by every method for every species\n",
    "            coresets_per_species_centroid[s] = coresets_per_species_centroid[s].intersection(reference_sets[method][0][s])\n",
    "total_per_cutoff = []\n",
    "total_genomes_per_cutoff = []\n",
    "num_per_cutoff = []\n",
    "num_per_cutoff_centroid = []\n",
    "coreset_per_cutoff = []\n",
    "coreset_per_cutoff_centroid = []    \n",
    "\n",
    "lb = 1\n",
    "for cutoff in range(lb, max_species+1): \n",
    "    cur_species = set()\n",
    "    cur_total = 0\n",
    "    for s in reference_sets[\"all\"][0]:\n",
    "        if len(reference_sets[\"all\"][0][s]) >= cutoff:\n",
    "            cur_species.add(s)\n",
    "            cur_total += len(reference_sets[\"all\"][0][s])\n",
    "    total_per_cutoff.append(len(cur_species))\n",
    "    total_genomes_per_cutoff.append(cur_total)\n",
    "    num_species_in_coreset = 0\n",
    "    num_species_in_coreset_centroid = 0\n",
    "    num_genomes_in_coreset = 0\n",
    "    num_genomes_in_coreset_centroid = 0\n",
    "    for species in cur_species:\n",
    "        if len(coresets_per_species[species]) > 0:\n",
    "            num_species_in_coreset += 1\n",
    "            num_genomes_in_coreset += len(coresets_per_species[species])\n",
    "        if len(coresets_per_species_centroid[species]) > 0:\n",
    "            num_species_in_coreset_centroid += 1\n",
    "            num_genomes_in_coreset_centroid += len(coresets_per_species_centroid[species])\n",
    "    num_per_cutoff.append(num_species_in_coreset)\n",
    "    num_per_cutoff_centroid.append(num_species_in_coreset_centroid)\n",
    "    coreset_per_cutoff.append(num_genomes_in_coreset)\n",
    "    coreset_per_cutoff_centroid.append(num_genomes_in_coreset_centroid)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(range(lb, max_species+1), total_per_cutoff, color=\"green\", linewidth=1, label=\"Total number of species\")\n",
    "ax.plot(range(lb, max_species+1), num_per_cutoff, color=\"blue\", alpha=0.5, label=\"Number of species in coreset (excl. centroid)\")\n",
    "ax.plot(range(lb, max_species+1), num_per_cutoff_centroid, color=\"orange\", alpha=0.5, label=\"Number of species in coreset (incl. centroid)\")\n",
    "ax.set_xlabel(\"Minimal number of genomes per species\")\n",
    "ax.set_ylabel(\"Number of species\")\n",
    "ax.set_xlim(lb, max_species)\n",
    "ax.set_xscale(\"log\", base=10)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_title(f\"NCBI Bacteria\")\n",
    "ax.legend()\n",
    "# Add annotation for sets with >= 2 genomes\n",
    "ax.vlines(2, ymin=0, ymax=num_per_cutoff_centroid[1], color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "ax.vlines(2, ymin=num_per_cutoff_centroid[1], ymax=num_per_cutoff[1], color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "ax.vlines(2, ymin=num_per_cutoff[1], ymax=total_per_cutoff[1], color=\"green\", linestyles=\":\", linewidth=1)\n",
    "ax.hlines(num_per_cutoff_centroid[1], xmin=lb, xmax=2, color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "ax.hlines(num_per_cutoff[1], xmin=lb, xmax=2, color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "ax.hlines(total_per_cutoff[1], xmin=lb, xmax=2, color=\"green\", linestyles=\":\", linewidth=1)\n",
    "xticks = list(ax.get_xticks()) + [2]\n",
    "yticks = list(ax.get_yticks()) + [num_per_cutoff_centroid[1]] +  [num_per_cutoff[1]] + [total_per_cutoff[1]]\n",
    "ax.set_yticks(sorted(set(yticks)))\n",
    "# Color\n",
    "for label in ax.get_yticklabels():\n",
    "    if label.get_text() == f\"{num_per_cutoff_centroid[1]}\":\n",
    "        label.set_color(\"orange\")\n",
    "        label.set_x(label.get_position()[0] - 0.05)\n",
    "    elif label.get_text() == f\"{num_per_cutoff[1]}\":\n",
    "        label.set_color(\"blue\") \n",
    "        label.set_x(label.get_position()[0] - 0.05)\n",
    "    elif label.get_text() == f\"{total_per_cutoff[1]}\":\n",
    "        label.set_color(\"green\")\n",
    "        label.set_x(label.get_position()[0] - 0.05)\n",
    "fig.savefig(f\"{OUTPUT_DIR}/coreset_species.pdf\", dpi=500, bbox_inches=\"tight\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#ax.plot(range(lb, max_species+1), total_genomes_per_cutoff, color=\"black\", linewidth=1, label=\"Total number of genomes\")\n",
    "ax.plot(range(lb, max_species+1), coreset_per_cutoff, color=\"blue\", alpha=0.5, label=\"Number of genomes in coreset (excl. centroid)\")\n",
    "ax.plot(range(lb, max_species+1), coreset_per_cutoff_centroid, color=\"orange\", alpha=0.5, label=\"Number of genomes in coreset (incl. centroid)\")\n",
    "ax.set_xlabel(\"Minimal number of genomes per species\")\n",
    "ax.set_ylabel(\"Number of genomes\")\n",
    "ax.set_xlim(lb, max_species)\n",
    "ax.set_xscale(\"log\", base=10)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_title(f\"NCBI Bacteria\")\n",
    "ax.legend()\n",
    "# Add annotation for sets with >= 2 genomes\n",
    "ax.vlines(2, ymin=0, ymax=coreset_per_cutoff_centroid[1], color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "ax.vlines(2, ymin=coreset_per_cutoff_centroid[1], ymax=coreset_per_cutoff[1], color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "ax.hlines(coreset_per_cutoff_centroid[1], xmin=lb, xmax=2, color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "ax.hlines(coreset_per_cutoff[1], xmin=lb, xmax=2, color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "xticks = list(ax.get_xticks()) + [2]\n",
    "yticks = list(ax.get_yticks()) + [coreset_per_cutoff_centroid[1]] +  [coreset_per_cutoff[1]]\n",
    "ax.set_yticks(sorted(set(yticks)))\n",
    "# Color\n",
    "for label in ax.get_yticklabels():\n",
    "    if label.get_text() == f\"{coreset_per_cutoff_centroid[1]}\":\n",
    "        label.set_color(\"orange\")\n",
    "        label.set_x(label.get_position()[0] - 0.05)\n",
    "    elif label.get_text() == f\"{coreset_per_cutoff[1]}\":\n",
    "        label.set_color(\"blue\")\n",
    "        label.set_x(label.get_position()[0] - 0.05)\n",
    "fig.savefig(f\"{OUTPUT_DIR}/{experiment}/coreset_genomes.pdf\", dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
