{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon, spearmanr\n",
    "from matplotlib.ticker import FuncFormatter, ScalarFormatter, LogLocator, LogFormatter\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SAMPLES = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "ABUNDANCES = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "METHODS = [\n",
    "    \"all\",\n",
    "\t\"centroid\",\n",
    "    \"ggrasp\",\n",
    "    \"vlq\",\n",
    "\t\"meshclust_0.95\",\n",
    "\t\"meshclust_0.99\",\n",
    "    \"gclust_0.95\",\n",
    "\t\"gclust_0.99\",\n",
    "\t\"gclust_0.999\",\n",
    "    \"vsearch_0.95\",\n",
    "    \"vsearch_0.99\",\n",
    "    \"vsearch_0.999\",\n",
    "    \"single-linkage_1\",\n",
    "    \"single-linkage_5\",\n",
    "    \"single-linkage_10\",\n",
    "    \"single-linkage_25\",\n",
    "    \"single-linkage_50\",\n",
    "    \"single-linkage_90\",\n",
    "    \"single-linkage_99\",\n",
    "\t\"complete-linkage_1\",\n",
    "    \"complete-linkage_5\",\n",
    "    \"complete-linkage_10\",\n",
    "    \"complete-linkage_25\",\n",
    "    \"complete-linkage_50\",\n",
    "    \"complete-linkage_90\",\n",
    "    \"complete-linkage_99\",\n",
    "\n",
    "]\n",
    "METHOD_LABELS = {\n",
    "    \"all\": \"All\",\n",
    "\t\"centroid\": \"Centroid\",\n",
    "    \"ggrasp\": \"GGRaSP\",\n",
    "    \"vlq\": \"VLQ\",\n",
    "\t\"meshclust_0.95\": \"MC-0.95\",\n",
    "\t\"meshclust_0.99\": \"MC-0.99\",\n",
    "    \"gclust_0.95\": \"GC-0.95\",\n",
    "\t\"gclust_0.99\": \"GC-0.99\",\n",
    "\t\"gclust_0.999\": \"GC-0.999\",\n",
    "    \"vsearch_0.95\": \"VS-0.95\",\n",
    "    \"vsearch_0.99\": \"VS-0.99\",\n",
    "    \"vsearch_0.999\": \"VS-0.999\",\n",
    "    \"single-linkage_1\": r\"SL-$P_{1}$\",\n",
    "    \"single-linkage_5\": r\"SL-$P_{5}$\",\n",
    "    \"single-linkage_10\": r\"SL-$P_{10}$\",\n",
    "    \"single-linkage_25\": r\"SL-$P_{25}$\",\n",
    "    \"single-linkage_50\": r\"SL-$P_{50}$\",\n",
    "    \"single-linkage_90\": r\"SL-$P_{90}$\",\n",
    "    \"single-linkage_99\": r\"SL-$P_{99}$\",\n",
    "\t\"complete-linkage_1\": r\"CL-$P_{1}$\",\n",
    "    \"complete-linkage_5\": r\"CL-$P_{5}$\",\n",
    "    \"complete-linkage_10\": r\"CL-$P_{10}$\",\n",
    "    \"complete-linkage_25\": r\"CL-$P_{25}$\",\n",
    "    \"complete-linkage_50\": r\"CL-$P_{50}$\",\n",
    "    \"complete-linkage_90\": r\"CL-$P_{90}$\",\n",
    "    \"complete-linkage_99\": r\"CL-$P_{99}$\",\n",
    "}\n",
    "EXPERIMENTS = [\"global\", \"country\", \"state\"]\n",
    "ALPHA = 0.05\n",
    "OUTPUT_DIR = \"figures/viruses\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(experiment):\n",
    "    \"\"\"\n",
    "    Determine all lineages that are present in reference and simulation genomes\n",
    "    \"\"\"\n",
    "    idx2lineage = []\n",
    "    lineage2idx = {}\n",
    "    # Add lineages from reference\n",
    "    with open(f\"root/reference_sets/{experiment}/all.tsv\", \"r\") as f_in:\n",
    "        next(f_in) #skip header\n",
    "        for line in f_in:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            lineage = line[0]\n",
    "            if lineage not in lineage2idx:\n",
    "                lineage2idx[lineage] = len(idx2lineage)\n",
    "                idx2lineage.append(lineage)\n",
    "    print(len(lineage2idx), \"unique lineages found in reference\")\n",
    "    # Add lineages from simulations\n",
    "    with open(f\"root/samples/1/metadata.tsv\", \"r\") as f_in:\n",
    "        next(f_in)\n",
    "        for line in f_in:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            lineage = line[11]\n",
    "            if lineage not in lineage2idx:\n",
    "                lineage2idx[lineage] = len(idx2lineage)\n",
    "                idx2lineage.append(lineage)\n",
    "    print(len(lineage2idx), \"unique lineages found in total\")\n",
    "\n",
    "    return idx2lineage, lineage2idx\n",
    "\n",
    "def generate_groundtruth(idx2lineage, lineage2idx):\n",
    "    # Map sequence ids to lineages\n",
    "    id2lineage = {}\n",
    "    with open(f\"root/samples/1/metadata.tsv\", \"r\") as f_in:\n",
    "        next(f_in)\n",
    "        for line in f_in:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            id = line[0]\n",
    "            lineage = line[11]\n",
    "            id2lineage[id] = lineage\n",
    "\n",
    "    abundances = np.zeros((len(SAMPLES)*len(ABUNDANCES), len(idx2lineage)), dtype=np.float64)\n",
    "    for sample in SAMPLES:\n",
    "        # Map sequence ids to genome length\n",
    "        id2length = {}\n",
    "        for record in SeqIO.parse(f\"root/samples/{sample}/sequences.tsv\", \"fasta\"):\n",
    "            id2length[record.id.strip().split(\"|\")[0]] = len(record.seq)\n",
    "        for record in SeqIO.parse(\"root/B.1.1.7_sequence.fasta\", \"fasta\"):\n",
    "            id2length[record.id.strip().split(\"|\")[0]] = len(record.seq)\n",
    "\n",
    "        for i, abundance in enumerate(ABUNDANCES):\n",
    "            nucleotides = {id: 0 for id in id2length.keys()}\n",
    "            linecount = 0\n",
    "            with open(f\"root/samples/{sample}/wwsim_B.1.1.7_sequence_ab{abundance}_1.fastq\", \"r\") as f_in:\n",
    "                for line in f_in:\n",
    "                    if linecount % 4 == 0:\n",
    "                        id = line[1:].strip().split(\"|\")[0]\n",
    "                    elif linecount % 4 == 1:\n",
    "                        nucleotides[id] += len(line.strip())             \n",
    "                    linecount += 1\n",
    "            linecount = 0\n",
    "            with open(f\"root/samples/{sample}/wwsim_B.1.1.7_sequence_ab{abundance}_2.fastq\", \"r\") as f_in:\n",
    "                for line in f_in:\n",
    "                    if linecount % 4 == 0:\n",
    "                        id = line[1:].strip().split(\"|\")[0]\n",
    "                    elif linecount % 4 == 1:\n",
    "                        nucleotides[id] += len(line.strip())             \n",
    "                    linecount += 1\n",
    "\n",
    "            for id in nucleotides:\n",
    "                try:\n",
    "                    lineage = id2lineage[id]\n",
    "                except: # not included in sequences file!\n",
    "                    lineage = \"B.1.1.7\"\n",
    "                abundances[sample-1 + i*len(SAMPLES), lineage2idx[lineage]] += nucleotides[id] / id2length[id]\n",
    "            abundances[sample-1 + i*len(SAMPLES), :] = abundances[sample-1 + i*len(SAMPLES), :] / np.sum(abundances[sample-1 + i*len(SAMPLES), :])\n",
    "\n",
    "    return abundances\n",
    "\n",
    "def read_estimations(method, experiment, lineage2idx):\n",
    "    basepath = f\"root/estimations/{experiment}\"\n",
    "    abundances = np.zeros((len(SAMPLES)*len(ABUNDANCES), len(lineage2idx)), dtype=np.float64)\n",
    "    for i, abundance in enumerate(ABUNDANCES):\n",
    "        for sample in SAMPLES:\n",
    "            with open(f\"{basepath}/{sample}/{method}_ab{abundance}_predictions.tsv\", \"r\") as f_in:\n",
    "                next(f_in)\n",
    "                next(f_in)\n",
    "                next(f_in) #skip preamble\n",
    "                for line in f_in:\n",
    "                    lineage, _, _, cur_abundance = line.strip().split(\"\\t\")\n",
    "                    cur_abundance = float(cur_abundance) / 100\n",
    "                    if cur_abundance > 0.001:\n",
    "                        abundances[sample-1 + i*len(SAMPLES), lineage2idx[lineage]] = cur_abundance\n",
    "            abundances[sample-1 + i*len(SAMPLES), :] = abundances[sample-1 + i*len(SAMPLES), :] / np.sum(abundances[sample-1 + i*len(SAMPLES), :])\n",
    "    return abundances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_PALETTE = {\n",
    "    \"1 - L1/2\": sns.color_palette(\"deep\")[0],\n",
    "    \"F1\": sns.color_palette(\"muted\")[1]\n",
    "}\n",
    "\n",
    "def plot_results(experiment, metrics, results, methods, pvalues_l1, pvalues_f1):\n",
    "    df = pd.DataFrame(metrics)\n",
    "    # Keep only rows where 'method' is in the provided methods list (by label)\n",
    "    method_labels = [METHOD_LABELS[m] for m in methods]\n",
    "    df = df[df[\"method\"].isin(method_labels)].copy()\n",
    "    fig = plt.figure()\n",
    "    g = sns.catplot(\n",
    "        data=df,\n",
    "        kind=\"bar\",\n",
    "        x=\"method\",\n",
    "        y=\"value\",\n",
    "        hue=\"metric\",\n",
    "        estimator=\"median\",\n",
    "        errorbar=(\"pi\", 80),\n",
    "        err_kws={\"linewidth\": 4},\n",
    "        width=0.9,\n",
    "        alpha=0.8,\n",
    "        order=[METHOD_LABELS[m] for m in methods[1:]],\n",
    "        palette=COLOR_PALETTE,\n",
    "    )\n",
    "    g.set_axis_labels(\"\", \"Score\", fontsize=16)\n",
    "    g.ax.axhline(y=np.median(results[\"all\"][\"L1\"]), xmin=0, xmax=1, color=COLOR_PALETTE[\"1 - L1/2\"], linestyle=\"--\", alpha=1, linewidth=2)\n",
    "    g.ax.axhline(y=np.median(results[\"all\"][\"F1\"]), xmin=0, xmax=1, color=COLOR_PALETTE[\"F1\"], linestyle=\"--\", alpha=1, linewidth=2)\n",
    "    g.ax.grid(True, which=\"major\", axis=\"y\", linestyle=\":\", alpha=0.5)\n",
    "\n",
    "    title_str = f\"{experiment.capitalize()}\"\n",
    "    plt.title(title_str, fontsize=20)\n",
    "\n",
    "    plt.xticks(fontsize=15, rotation=90, ha=\"right\")\n",
    "    plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0], fontsize=13)\n",
    "    plt.ylim([0.0, 1.05])\n",
    "\n",
    "    methods_labels = [METHOD_LABELS[m] for m in methods[1:]]  # display names\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        # one BarContainer per metric\n",
    "        for metric, container in zip([\"1 - L1/2\", \"F1\"], ax.containers):\n",
    "            # one bar per method\n",
    "            for method_label, bar in zip(methods_labels, container.patches):\n",
    "                # find matching df subset\n",
    "                group = df[(df[\"metric\"] == metric) & (df[\"method\"] == method_label)]\n",
    "                if group.empty:\n",
    "                    continue\n",
    "\n",
    "                y_90 = np.percentile(group[\"value\"], 90)\n",
    "                # choose p-values precomputed as dicts keyed by method_label\n",
    "                pval_dict = pvalues_f1 if metric == \"F1\" else pvalues_l1\n",
    "                if pval_dict.get(method_label, 1.0) < ALPHA:\n",
    "                    x_center = bar.get_x() + bar.get_width() / 2\n",
    "                    ax.text(\n",
    "                        x_center,\n",
    "                        y_90 + 0.025,     # just above the bar\n",
    "                        f\"\\u2217\",          # your star or method name\n",
    "                        ha=\"center\",\n",
    "                        va=\"bottom\",\n",
    "                        fontsize=10,\n",
    "                        fontweight=\"bold\"\n",
    "                    )\n",
    "    # Fix legend\n",
    "    g.ax.legend(title=\"\", fontsize=15, ncol=2)\n",
    "    \n",
    "    g.figure.set_size_inches(8, 6)\n",
    "    g.figure.tight_layout()\n",
    "    g.savefig(f\"${OUTPUT_DIR}/viruses/{experiment}/barplot.svg\", dpi=500, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_genomes(experiment, results):\n",
    "    median_outcomes_l1 = np.array([np.median(results[method][\"L1\"]) for method in METHODS], dtype=np.float64)\n",
    "    median_outcomes_f1 = np.array([np.median(results[method][\"F1\"]) for method in METHODS], dtype=np.float64)\n",
    "    genome_counts = np.array([results[method][\"genomes\"] for method in METHODS], dtype=np.int64)\n",
    "\n",
    "    rho_l1, _ = spearmanr(genome_counts, median_outcomes_l1, nan_policy=\"omit\")\n",
    "    rho_f1, _ = spearmanr(genome_counts, median_outcomes_f1, nan_policy=\"omit\")\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = sns.scatterplot(x=genome_counts, y=median_outcomes_l1, s=100, color=sns.color_palette(\"deep\")[0], label=\"1 - L1/2\", edgecolor=\"black\", alpha=0.5)\n",
    "    sns.scatterplot(x=genome_counts, y=median_outcomes_f1, s=100, color=sns.color_palette(\"muted\")[1], label=\"F1\", edgecolor=\"black\", alpha=0.5, ax=ax)\n",
    "\n",
    "    plt.xlabel(\"Number of genomes\", fontsize=16)\n",
    "    plt.ylabel(\"Score\", fontsize=16)\n",
    "    ax.grid(True, which=\"major\", axis=\"y\", linestyle=\":\", alpha=0.5)\n",
    "    plt.title(rf\"$\\rho(1-L1/2)={rho_l1:.3f}$, $\\rho(F1)={rho_f1:.3f}$\", fontsize=16)\n",
    "    plt.ylim([0, 1.05])\n",
    "    # Account for scales\n",
    "    if experiment == \"global\":\n",
    "        plt.xlim([0, max(genome_counts)+3000])\n",
    "    elif experiment == \"country\":\n",
    "        plt.xlim([0, max(genome_counts)+500])\n",
    "    else:\n",
    "        plt.xlim([0, max(genome_counts)+100])\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0], fontsize=13)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.legend(title=\"\", fontsize=15, ncol=2)\n",
    "    plt.tight_layout()\n",
    "    #ax.set_xscale(\"log\", base=10)\n",
    "    fig.savefig(f\"${OUTPUT_DIR}/viruses/{experiment}/l1_f1_genomes.svg\", dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_experiment = {}\n",
    "metrics_per_experiment = {}\n",
    "num_genomes_per_experiment = {}\n",
    "for experiment in [\"state\", \"country\", \"global\"]:\n",
    "    idx2lineage, lineage2idx = create_mapping(experiment)\n",
    "    groundtruth = generate_groundtruth(idx2lineage, lineage2idx)\n",
    "\n",
    "    results_per_experiment[experiment] = {}\n",
    "    metrics_per_experiment[experiment] = []\n",
    "\n",
    "    for method in METHODS:\n",
    "        cur_results = read_estimations(method, experiment, lineage2idx)\n",
    "\n",
    "        num_genomes = 0\n",
    "        filepath = f\"root/reference_sets/{experiment}/{method}.tsv\"\n",
    "        with open(filepath, \"r\") as f_in:\n",
    "            next(f_in) #skip header\n",
    "            for line in f_in:\n",
    "                num_genomes += 1\n",
    "\n",
    "        results_per_experiment[experiment][method] = {\n",
    "            \"L1\": [1.0 - np.sum( np.abs(cur_results[x, :] - groundtruth[x, :])) / 2.0 for x in range(len(SAMPLES)*len(ABUNDANCES))],\n",
    "            \"F1\": [f1_score(groundtruth[x, :] > 0, cur_results[x, :] > 0, zero_division=1) for x in range(len(SAMPLES)*len(ABUNDANCES))],\n",
    "            \"genomes\": num_genomes,\n",
    "        }\n",
    "\n",
    "        for x in range(len(SAMPLES)*len(ABUNDANCES)):\n",
    "            metrics_per_experiment[experiment].append(\n",
    "                {\n",
    "                    \"method\": METHOD_LABELS[method],\n",
    "                    \"metric\": \"1 - L1/2\",\n",
    "                    \"value\": results_per_experiment[experiment][method][\"L1\"][x],\n",
    "                    \"genomes\": num_genomes\n",
    "                }\n",
    "            )\n",
    "            metrics_per_experiment[experiment].append(\n",
    "                {\n",
    "                    \"method\": METHOD_LABELS[method],\n",
    "                    \"metric\": \"F1\",\n",
    "                    \"value\": results_per_experiment[experiment][method][\"F1\"][x],\n",
    "                    \"genomes\": num_genomes\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run plotting\n",
    "**NOTE**: We aggregate results over all abundances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine, per method group, the best overal performance based on average median L1 and F1 score across experiments\n",
    "method_groups = [\n",
    "    [\"all\"],\n",
    "\t[\"centroid\"],\n",
    "    [\"ggrasp\"],\n",
    "    [\"vlq\"],\n",
    "\t[\"meshclust_0.95\", \"meshclust_0.99\"],\n",
    "    [\"gclust_0.95\", \"gclust_0.99\", \"gclust_0.999\"],\n",
    "    [\"vsearch_0.95\", \"vsearch_0.99\", \"vsearch_0.999\"],\n",
    "    [\"single-linkage_1\",\n",
    "    \"single-linkage_5\",\n",
    "    \"single-linkage_10\",\n",
    "    \"single-linkage_25\",\n",
    "    \"single-linkage_50\",\n",
    "    \"single-linkage_90\",\n",
    "    \"single-linkage_99\"],\n",
    "\t[\"complete-linkage_1\",\n",
    "    \"complete-linkage_5\",\n",
    "    \"complete-linkage_10\",\n",
    "    \"complete-linkage_25\",\n",
    "    \"complete-linkage_50\",\n",
    "    \"complete-linkage_90\",\n",
    "    \"complete-linkage_99\"],\n",
    "]\n",
    "# Find best method per group\n",
    "final_methods = []\n",
    "for method_group in method_groups:\n",
    "    if len(method_group) == 1:\n",
    "        final_methods.append(method_group[0])\n",
    "    else:\n",
    "        best_method = None\n",
    "        best_score = -1\n",
    "        for method in method_group:\n",
    "            avg_median_l1 = np.mean([np.median(results_per_experiment[exp][method][\"L1\"]) for exp in [\"state\", \"country\", \"global\"]])\n",
    "            avg_median_f1 = np.mean([np.median(results_per_experiment[exp][method][\"F1\"]) for exp in [\"state\", \"country\", \"global\"]])\n",
    "            score = avg_median_l1 + avg_median_f1\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_method = method\n",
    "        final_methods.append(best_method)\n",
    "final_methods = [\n",
    "    \"all\",\n",
    "\t\"centroid\",\n",
    "    \"ggrasp\",\n",
    "    \"vlq\",\n",
    "\t\"meshclust_0.95\",\n",
    "\t\"meshclust_0.99\",\n",
    "    \"gclust_0.95\",\n",
    "\t\"gclust_0.99\",\n",
    "\t\"gclust_0.999\",\n",
    "    \"vsearch_0.95\",\n",
    "    \"vsearch_0.99\",\n",
    "    \"vsearch_0.999\",\n",
    "    \"single-linkage_1\",\n",
    "    \"single-linkage_25\",\n",
    "    \"single-linkage_99\",\n",
    "\t\"complete-linkage_1\",\n",
    "    \"complete-linkage_25\",\n",
    "    \"complete-linkage_99\",\n",
    "]\n",
    "final_methods = METHODS # override for final plots\n",
    "# Determine p-values and significance\n",
    "pvalues_l1_per_experiment = {}\n",
    "pvalues_l1_corrected_per_experiment = {}\n",
    "pvalues_f1_per_experiment = {}\n",
    "pvalues_f1_corrected_per_experiment = {}\n",
    "for experiment in [\"state\", \"country\", \"global\"]:\n",
    "    results = results_per_experiment[experiment]\n",
    "    metrics = metrics_per_experiment[experiment]\n",
    "\n",
    "    pvalues_l1 = np.ones((len(METHODS)-1,), dtype=np.float64)\n",
    "    pvalues_f1 = np.ones((len(METHODS)-1,), dtype=np.float64)\n",
    "    for i, method in enumerate(METHODS[1:]):\n",
    "        # L1\n",
    "        try:\n",
    "            _, pval = wilcoxon(\n",
    "                results[method][\"L1\"],\n",
    "                results[\"all\"][\"L1\"],\n",
    "                alternative=\"greater\"\n",
    "            )\n",
    "        except:\n",
    "            pval = 1.0\n",
    "        pvalues_l1[i] = pval\n",
    "        # F1\n",
    "        try:\n",
    "            _, pval = wilcoxon(\n",
    "                results[method][\"F1\"],\n",
    "                results[\"all\"][\"F1\"],\n",
    "                alternative=\"greater\"\n",
    "            )\n",
    "        except:\n",
    "            pval = 1.0\n",
    "        pvalues_f1[i] = pval\n",
    "    # Multiple testing correction (Benjamini-Hochberg)\n",
    "    methods_for_pvalues = [METHOD_LABELS[m] for m in METHODS[1:]]\n",
    "    pvalues_l1_per_experiment[experiment] = dict(zip(methods_for_pvalues, pvalues_l1))\n",
    "    pvalues_l1_corrected_per_experiment[experiment] = dict(zip(methods_for_pvalues, multipletests(pvalues_l1, method=\"fdr_bh\")[1]))\n",
    "    pvalues_f1_per_experiment[experiment] = dict(zip(methods_for_pvalues, pvalues_f1))\n",
    "    pvalues_f1_corrected_per_experiment[experiment] = dict(zip(methods_for_pvalues, multipletests(pvalues_f1, method=\"fdr_bh\")[1]))\n",
    "    print(f\"Experiment: {experiment}\")\n",
    "    print(multipletests(pvalues_l1, method=\"fdr_bh\")[1])\n",
    "\n",
    "for experiment in [\"global\", \"country\", \"state\"]:\n",
    "    plot_results(experiment, metrics_per_experiment[experiment], results_per_experiment[experiment], final_methods, pvalues_l1_corrected_per_experiment[experiment], pvalues_f1_corrected_per_experiment[experiment])\n",
    "    plot_genomes(experiment, results_per_experiment[experiment])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate correlation over all reference sets (across experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_l1 = []\n",
    "median_f1 = []\n",
    "genomes = []\n",
    "for experiment in [\"state\", \"country\", \"global\"]:\n",
    "    for method in METHODS:\n",
    "        median_l1.append(np.median(results_per_experiment[experiment][method][\"L1\"]))\n",
    "        median_f1.append(np.median(results_per_experiment[experiment][method][\"F1\"]))\n",
    "        genomes.append(results_per_experiment[experiment][method][\"genomes\"])\n",
    "\n",
    "rho_l1, _ = spearmanr(genomes, median_l1, nan_policy=\"omit\")\n",
    "rho_f1, _ = spearmanr(genomes, median_f1, nan_policy=\"omit\")\n",
    "\n",
    "print(f\"Overall correlation genomes vs L1: {rho_l1:.3f}\")\n",
    "print(f\"Overall correlation genomes vs F1: {rho_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
