{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import seaborn as sns\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = [\n",
    "    \"global\",\n",
    "    \"country\",\n",
    "    \"state\",\n",
    "]\n",
    "METHODS = [\n",
    "    \"all\",\n",
    "\t\"centroid\",\n",
    "    \"ggrasp\",\n",
    "    \"vlq\",\n",
    "\t\"meshclust_0.95\",\n",
    "\t\"meshclust_0.99\",\n",
    "    \"gclust_0.95\",\n",
    "\t\"gclust_0.99\",\n",
    "\t\"gclust_0.999\",\n",
    "    \"vsearch_0.95\",\n",
    "    \"vsearch_0.99\",\n",
    "    \"vsearch_0.999\",\n",
    "    \"single-linkage_1\",\n",
    "    \"single-linkage_5\",\n",
    "    \"single-linkage_10\",\n",
    "    \"single-linkage_25\",\n",
    "    \"single-linkage_50\",\n",
    "    \"single-linkage_90\",\n",
    "    \"single-linkage_99\",\n",
    "\t\"complete-linkage_1\",\n",
    "    \"complete-linkage_5\",\n",
    "    \"complete-linkage_10\",\n",
    "    \"complete-linkage_25\",\n",
    "    \"complete-linkage_50\",\n",
    "    \"complete-linkage_90\",\n",
    "    \"complete-linkage_99\",\n",
    "]\n",
    "print(len(METHODS))\n",
    "METHOD_LABELS = {\n",
    "    \"all\": \"All\",\n",
    "\t\"centroid\": \"Centroid\",\n",
    "    \"ggrasp\": \"GGRaSP\",\n",
    "    \"vlq\": \"VLQ\",\n",
    "\t\"meshclust_0.95\": \"MC-0.95\",\n",
    "\t\"meshclust_0.99\": \"MC-0.99\",\n",
    "    \"gclust_0.95\": \"GC-0.95\",\n",
    "\t\"gclust_0.99\": \"GC-0.99\",\n",
    "\t\"gclust_0.999\": \"GC-0.999\",\n",
    "    \"vsearch_0.95\": \"VS-0.95\",\n",
    "    \"vsearch_0.99\": \"VS-0.99\",\n",
    "    \"vsearch_0.999\": \"VS-0.999\",\n",
    "    \"single-linkage_1\": r\"SL-$P_{1}$\",\n",
    "    \"single-linkage_5\": r\"SL-$P_{5}$\",\n",
    "    \"single-linkage_10\": r\"SL-$P_{10}$\",\n",
    "    \"single-linkage_25\": r\"SL-$P_{25}$\",\n",
    "    \"single-linkage_50\": r\"SL-$P_{50}$\",\n",
    "    \"single-linkage_90\": r\"SL-$P_{90}$\",\n",
    "    \"single-linkage_99\": r\"SL-$P_{99}$\",\n",
    "\t\"complete-linkage_1\": r\"CL-$P_{1}$\",\n",
    "    \"complete-linkage_5\": r\"CL-$P_{5}$\",\n",
    "    \"complete-linkage_10\": r\"CL-$P_{10}$\",\n",
    "    \"complete-linkage_25\": r\"CL-$P_{25}$\",\n",
    "    \"complete-linkage_50\": r\"CL-$P_{50}$\",\n",
    "    \"complete-linkage_90\": r\"CL-$P_{90}$\",\n",
    "    \"complete-linkage_99\": r\"CL-$P_{99}$\",\n",
    "}\n",
    "OUTPUT_DIR = \"figures/viruses\"\n",
    "\n",
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CI(refset1, refset2):\n",
    "    if type(refset1) is np.ndarray:\n",
    "        intersection = np.sum(np.minimum(refset1, refset2))\n",
    "        return [intersection/np.sum(refset1), intersection/np.sum(refset2)]\n",
    "    else:\n",
    "        intersection = len(refset1.intersection(refset2))\n",
    "        return [intersection/len(refset1), intersection/len(refset2)]\n",
    "\n",
    "def determine_nonsingletons(experiment):\n",
    "    \"\"\"\n",
    "    This function determines the lineage which have more than one genome and should be included\n",
    "    in the overlap analysis.\n",
    "    \"\"\"\n",
    "    path = f\"root/reference_sets/{experiment}/all.tsv\"\n",
    "    count_per_lineage = {}\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            lineage, _, _ = line.strip().split(\"\\t\")\n",
    "            if lineage not in count_per_lineage:\n",
    "                count_per_lineage[lineage] = 0\n",
    "            count_per_lineage[lineage] += 1\n",
    "    nonsingletons = [int(lineage) for lineage, count in count_per_lineage.items() if count > 1]\n",
    "    return sorted(nonsingletons)\n",
    "    \n",
    "def determine_content(experiment, method, nonsingletons):\n",
    "    \"\"\"\n",
    "    This function determines the content of a reference set for a given experiment and method.\n",
    "    NOTE: If a method was used with a threshold (e.g. gclust and 0.95) then the method name\n",
    "    should be provided as gclust_0.95.\n",
    "    \"\"\"\n",
    "    path = f\"root/reference_sets/{experiment}/{method}.tsv\"\n",
    "    counts = np.zeros(len(nonsingletons), dtype=int)\n",
    "    items = set()\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            lineage, accession, _ = line.strip().split(\"\\t\")\n",
    "            lineage = int(lineage)\n",
    "            if lineage in nonsingletons:\n",
    "                idx = nonsingletons.index(lineage)\n",
    "                counts[idx] += 1\n",
    "                items.add(accession)\n",
    "    return counts, items\n",
    "\n",
    "def simulate(N, n1, n2, obs_ci, num_simulations=10_000, seed=None):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo simulation to estimate the probability of observing a certain overlap between two sets.\n",
    "    NOTE: We specifically test whether the selection of n2 is independent of n1, i.e. we test the null hypothesis\n",
    "    that the selection of n2 is random with respect to n1 (thus the n1 draws are fixed). This means that the p-values \n",
    "    we obtain are one-sided, i.e. we only test whether the overlap is significantly greater than expected by chance.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    N: numpy.ndarray\n",
    "        A 1D vector with an entry for every nonsingleton lineage, indicating the total number of genomes\n",
    "        for that lineage that could be selected (i.e. are in the \"all\" reference set).\n",
    "    n1: numpy.ndarray\n",
    "        A 1D vector with an entry for every nonsingleton lineage, indicating the number of genomes\n",
    "        selected in the first set.\n",
    "    n2: numpy.ndarray\n",
    "        A 1D vector with an entry for every nonsingleton lineage, indicating the number of genomes\n",
    "        selected in the second set.\n",
    "    num_simulations: int\n",
    "        The number of Monte Carlo simulations to perform.\n",
    "    seed: int, optional\n",
    "        Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = np.asarray(N, dtype=int)\n",
    "    n1 = np.asarray(n1, dtype=int)\n",
    "    n2 = np.asarray(n2, dtype=int)\n",
    "    G = N.shape[0]\n",
    "\n",
    "    # simulate overlaps\n",
    "    sim_totals = np.zeros(num_simulations, dtype=int)\n",
    "    for Ng, n1g, n2g in zip(N, n1, n2):\n",
    "        draws = rng.hypergeometric(\n",
    "            ngood=int(n1g),\n",
    "            nbad=int(Ng-n1g),\n",
    "            nsample=int(n2g),\n",
    "            size=num_simulations\n",
    "        )\n",
    "        sim_totals += draws\n",
    "\n",
    "    sim_ci = sim_totals / np.sum(n2)\n",
    "\n",
    "    # Estimate p-values\n",
    "    def pval(sim, obs):\n",
    "        count = np.sum(sim >= obs)\n",
    "        p = (1 + count) / (1 + num_simulations)\n",
    "        se = sqrt(p * (1 - p) / num_simulations)\n",
    "        return p, se\n",
    "\n",
    "    return pval(sim_ci, obs_ci)\n",
    "\n",
    "def BH_adjust(pvalues, alpha):\n",
    "    \"\"\"\n",
    "    Benjamini-Hochberg procedure to control the false discovery rate (FDR) for multiple hypothesis testing.\n",
    "    \"\"\"\n",
    "    M = pvalues.shape[0]\n",
    "    \n",
    "    mask = ~np.eye(M, dtype=bool)\n",
    "    pvec = pvalues[mask]\n",
    "\n",
    "    m = len(pvec)\n",
    "\n",
    "    order = np.argsort(pvec)\n",
    "    psorted = pvec[order]\n",
    "    ranks = np.arange(1, m+1)\n",
    "    adj_sorted = psorted * m / ranks\n",
    "    adj_sorted = np.minimum.accumulate(adj_sorted[::-1])[::-1]\n",
    "    adj = np.empty_like(pvec)\n",
    "    adj[order] = np.minimum(adj_sorted, 1.0)\n",
    "\n",
    "    adj_pvalues = np.ones_like(pvalues)\n",
    "    adj_pvalues[mask] = adj\n",
    "    significant = adj_pvalues < alpha\n",
    "    return significant, adj_pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual plotting script\n",
    "This generates the plots in Figure 2 as well as Supplementary Figures S4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in EXPERIMENTS: # iterate over experiments\n",
    "    # Determine nonsingletons and reference sets\n",
    "    ns = determine_nonsingletons(experiment)\n",
    "    reference_sets = {\n",
    "        method: determine_content(experiment, method, ns) for method in METHODS\n",
    "    }\n",
    "    # Initialize matrices to store containment indices and p-values\n",
    "    containment_indices = np.ones((len(METHODS), len(METHODS)), dtype=np.float64)\n",
    "    pvalues = np.ones((len(METHODS), len(METHODS)), dtype=np.float64)\n",
    "    annot_matrix = np.empty_like(containment_indices, dtype=object) # annotation matrix for plotting\n",
    "    # Calculate containment indices and p-values for all method pairs\n",
    "    for i, method1 in tqdm(enumerate(METHODS)):\n",
    "        for j, method2 in enumerate(METHODS):\n",
    "            if i != j:\n",
    "                n1, r1 = reference_sets[method1]\n",
    "                n2, r2 = reference_sets[method2]\n",
    "                obs_ci = calculate_CI(r1, r2)[1]\n",
    "                containment_indices[j, i] = obs_ci\n",
    "                pvalues[j,i] = simulate(reference_sets[\"all\"][0], n1, n2, obs_ci, seed=i*10000 + j)[0]\n",
    "    # Correct for multiple testing\n",
    "    significant_pairs, _ = BH_adjust(pvalues, alpha=ALPHA)\n",
    "    for i, _ in tqdm(enumerate(METHODS)):\n",
    "        for j, _ in enumerate(METHODS):\n",
    "            if significant_pairs[i,j]:\n",
    "                annot_matrix[i,j] = f\"{containment_indices[i,j]:.2f}*\"\n",
    "            else:\n",
    "                annot_matrix[i,j] = f\"{containment_indices[i,j]:.2f}\"\n",
    "    # Start plotting\n",
    "    method_names = [METHOD_LABELS[method] for method in METHODS]\n",
    "    fig = plt.figure()\n",
    "    sns.heatmap(\n",
    "        containment_indices[:, 1:], \n",
    "        annot=annot_matrix[:, 1:], \n",
    "        cmap=\"Greys\",\n",
    "        cbar=True,\n",
    "        linewidth=0.5,\n",
    "        xticklabels=method_names[1:],\n",
    "        yticklabels=method_names,\n",
    "        fmt=\"\",\n",
    "        annot_kws={\"size\": 4},\n",
    "        )\n",
    "    plt.title(f\"{experiment.capitalize()}\", size=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/{experiment}/containment_indices.pdf\", dpi=500, bbox_inches=\"tight\") #assumes folders etc exist\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core genomes figure\n",
    "This will produce the figures in Supplementary Figure S6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_content_coreset(experiment, method):\n",
    "    path = f\"root/reference_sets/{experiment}/{method}.tsv\"\n",
    "    genomes_per_lineage = {}\n",
    "    succesfully_selected = set()\n",
    "    with open(path, \"r\") as f_in:\n",
    "        for line in f_in:\n",
    "            lineage, accession, selected = line.strip().split(\"\\t\")\n",
    "            if lineage not in genomes_per_lineage:\n",
    "                genomes_per_lineage[lineage] = set()\n",
    "            genomes_per_lineage[lineage].add(accession)\n",
    "            if selected == \"+\": # account for lineage where selection method failed as these were randomly selected\n",
    "                succesfully_selected.add(lineage)\n",
    "    return genomes_per_lineage, succesfully_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The idea here is to generate a figure (one per experiment) that shows how many lineage (percentually) have a genome in the core set. The x-axis shows the\n",
    "cut-off (i.e. the minimum number of genomes in \"all\") and the y-axis shows the percentage of lineage with at least one genome in the core set.\n",
    "This requires:\n",
    "    - Determining the which genomes are selected for which lineage for all methods\n",
    "    - For each cut-off, determine the number of lineage that have at least one genome in the core set\n",
    "        + this can be achieved using set intersections\n",
    "\"\"\"\n",
    "for experiment in EXPERIMENTS:\n",
    "    reference_sets = {\n",
    "        method: determine_content_coreset(experiment, method) for method in METHODS\n",
    "    } #maps method to (genomes per lineage, successful lineage)\n",
    "    max_lineage = 0 #max for the x-axis -> max number of genomes in \"all\" for any lineage\n",
    "    # Coresets per lineage\n",
    "    coresets_per_lineage = {}\n",
    "    coresets_per_lineage_centroid = {}\n",
    "    for s in reference_sets[\"all\"][0]:\n",
    "        max_lineage = max(max_lineage, len(reference_sets[\"all\"][0][s]))\n",
    "        coresets_per_lineage[s] = reference_sets[\"all\"][0][s].copy()\n",
    "        coresets_per_lineage_centroid[s] = reference_sets[\"all\"][0][s].copy()\n",
    "        coresets_per_lineage_centroid[s] = coresets_per_lineage_centroid[s].intersection(reference_sets[\"centroid\"][0][s])\n",
    "        for method in METHODS[2:]: #skip 'all' and 'centroid'\n",
    "            if s in reference_sets[method][1]: #only consider lineage where method succeeded\n",
    "                coresets_per_lineage[s] = coresets_per_lineage[s].intersection(reference_sets[method][0][s]) #contains the genomes shared by every method for every lineage\n",
    "                coresets_per_lineage_centroid[s] = coresets_per_lineage_centroid[s].intersection(reference_sets[method][0][s])\n",
    "    total_per_cutoff = []\n",
    "    total_genomes_per_cutoff = []\n",
    "    num_per_cutoff = []\n",
    "    num_per_cutoff_centroid = []\n",
    "    coreset_per_cutoff = []\n",
    "    coreset_per_cutoff_centroid = []\n",
    "\n",
    "    lb = 1\n",
    "    for cutoff in range(lb, max_lineage+1):\n",
    "        cur_lineage = set()\n",
    "        cur_total = 0\n",
    "        for s in reference_sets[\"all\"][0]:\n",
    "            if len(reference_sets[\"all\"][0][s]) >= cutoff:\n",
    "                cur_lineage.add(s)\n",
    "                cur_total += len(reference_sets[\"all\"][0][s])\n",
    "        total_per_cutoff.append(len(cur_lineage))\n",
    "        total_genomes_per_cutoff.append(cur_total)\n",
    "        num_lineage_in_coreset = 0\n",
    "        num_lineage_in_coreset_centroid = 0\n",
    "        num_genomes_in_coreset = 0\n",
    "        num_genomes_in_coreset_centroid = 0\n",
    "        for lineage in cur_lineage:\n",
    "            if len(coresets_per_lineage[lineage]) > 0:\n",
    "                num_lineage_in_coreset += 1\n",
    "                num_genomes_in_coreset += len(coresets_per_lineage[lineage])\n",
    "            if len(coresets_per_lineage_centroid[lineage]) > 0:\n",
    "                num_lineage_in_coreset_centroid += 1\n",
    "                num_genomes_in_coreset_centroid += len(coresets_per_lineage_centroid[lineage])\n",
    "        num_per_cutoff.append(num_lineage_in_coreset)\n",
    "        num_per_cutoff_centroid.append(num_lineage_in_coreset_centroid)\n",
    "        coreset_per_cutoff.append(num_genomes_in_coreset)\n",
    "        coreset_per_cutoff_centroid.append(num_genomes_in_coreset_centroid)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(range(lb, max_lineage+1), total_per_cutoff, color=\"green\", linewidth=1, label=\"Total number of lineage\")\n",
    "    ax.plot(range(lb, max_lineage+1), num_per_cutoff, color=\"blue\", alpha=0.5, label=\"Number of lineage in coreset (excl. centroid)\")\n",
    "    ax.plot(range(lb, max_lineage+1), num_per_cutoff_centroid, color=\"orange\", alpha=0.5, label=\"Number of lineage in coreset (incl. centroid)\")\n",
    "    ax.set_xlabel(\"Minimal number of genomes per lineage\")\n",
    "    ax.set_ylabel(\"Number of lineage\")\n",
    "    ax.set_xlim(lb, max_lineage)\n",
    "    ax.set_xscale(\"log\", base=10)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_title(f\"Experiment: {experiment.capitalize()}\")\n",
    "    ax.legend()\n",
    "    # Add annotation for sets with >= 2 genomes\n",
    "    ax.vlines(2, ymin=0, ymax=num_per_cutoff_centroid[1], color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "    ax.vlines(2, ymin=num_per_cutoff_centroid[1], ymax=num_per_cutoff[1], color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "    ax.vlines(2, ymin=num_per_cutoff[1], ymax=total_per_cutoff[1], color=\"green\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(num_per_cutoff_centroid[1], xmin=lb, xmax=2, color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(num_per_cutoff[1], xmin=lb, xmax=2, color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(total_per_cutoff[1], xmin=lb, xmax=2, color=\"green\", linestyles=\":\", linewidth=1)\n",
    "    xticks = list(ax.get_xticks()) + [2]\n",
    "    yticks = list(ax.get_yticks()) + [num_per_cutoff_centroid[1]] +  [num_per_cutoff[1]] + [total_per_cutoff[1]]\n",
    "    ax.set_yticks(sorted(set(yticks)))\n",
    "    # Color\n",
    "    for label in ax.get_yticklabels():\n",
    "        if label.get_text() == f\"{num_per_cutoff_centroid[1]}\":\n",
    "            label.set_color(\"orange\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "        elif label.get_text() == f\"{num_per_cutoff[1]}\":\n",
    "            label.set_color(\"blue\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "        elif label.get_text() == f\"{total_per_cutoff[1]}\":\n",
    "            label.set_color(\"green\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/{experiment}/coreset_lineage.pdf\", dpi=500, bbox_inches=\"tight\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    #ax.plot(range(lb, max_lineage+1), total_genomes_per_cutoff, color=\"black\", linewidth=1, label=\"Total number of genomes\")\n",
    "    ax.plot(range(lb, max_lineage+1), coreset_per_cutoff, color=\"blue\", alpha=0.5, label=\"Number of genomes in coreset (excl. centroid)\")\n",
    "    ax.plot(range(lb, max_lineage+1), coreset_per_cutoff_centroid, color=\"orange\", alpha=0.5, label=\"Number of genomes in coreset (incl. centroid)\")\n",
    "    ax.set_xlabel(\"Minimal number of genomes per lineage\")\n",
    "    ax.set_ylabel(\"Number of genomes\")\n",
    "    ax.set_xlim(lb, max_lineage)\n",
    "    ax.set_xscale(\"log\", base=10)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_title(f\"Experiment: {experiment.capitalize()}\")\n",
    "    ax.legend()\n",
    "    # Add annotation for sets with >= 2 genomes\n",
    "    ax.vlines(2, ymin=0, ymax=coreset_per_cutoff_centroid[1], color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "    ax.vlines(2, ymin=coreset_per_cutoff_centroid[1], ymax=coreset_per_cutoff[1], color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(coreset_per_cutoff_centroid[1], xmin=lb, xmax=2, color=\"orange\", linestyles=\":\", linewidth=1)\n",
    "    ax.hlines(coreset_per_cutoff[1], xmin=lb, xmax=2, color=\"blue\", linestyles=\":\", linewidth=1)\n",
    "    xticks = list(ax.get_xticks()) + [2]\n",
    "    yticks = list(ax.get_yticks()) + [coreset_per_cutoff_centroid[1]] +  [coreset_per_cutoff[1]]\n",
    "    ax.set_yticks(sorted(set(yticks)))\n",
    "    # Color\n",
    "    for label in ax.get_yticklabels():\n",
    "        if label.get_text() == f\"{coreset_per_cutoff_centroid[1]}\":\n",
    "            label.set_color(\"orange\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "        elif label.get_text() == f\"{coreset_per_cutoff[1]}\":\n",
    "            label.set_color(\"blue\")\n",
    "            label.set_x(label.get_position()[0] - 0.05)\n",
    "    fig.savefig(f\"{OUTPUT_DIR}/{experiment}/coreset_genomes.pdf\", dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
